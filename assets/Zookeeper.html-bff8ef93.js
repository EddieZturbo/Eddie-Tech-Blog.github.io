import{_ as s,W as i,X as a,Z as e,a1 as t,$ as n,Y as r,F as l}from"./framework-e28ace55.js";const d={},c=e("h1",{id:"zookeeper",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#zookeeper","aria-hidden":"true"},"#"),t(" Zookeeper")],-1),h=e("p",null,[e("img",{src:"https://eddie-typora-image.oss-cn-shenzhen.aliyuncs.com/typora-user-images/image-20221206112643989.png",alt:"image-20221206112643989"})],-1),p=e("p",null,[e("img",{src:"https://eddie-typora-image.oss-cn-shenzhen.aliyuncs.com/typora-user-images/image-20230408170626313.png",alt:"image-20230408170626313"})],-1),g={href:"https://zookeeper.apache.org/",target:"_blank",rel:"noopener noreferrer"},u=r('<p><strong>分布式应用程序协调服务软件</strong></p><h2 id="zookeeper-overview" tabindex="-1"><a class="header-anchor" href="#zookeeper-overview" aria-hidden="true">#</a> Zookeeper - OverView</h2><blockquote><p>ZooKeeper 是 Apache 软件基金会的一个软件项目，它为大型<strong>分布式</strong>计算提供开源的<strong>分布式配置服务</strong>、<strong>同步服务</strong>和<strong>命名注册</strong>。</p><p>ZooKeeper 的架构通过冗余服务实现高可用性。</p><p>Zookeeper 的设计目标是将那些复杂且容易出错的分布式一致性服务封装起来，构成一个高效可靠的原语集，并以一系列简单易用的接口提供给用户使用。</p><p>一个典型的分布式数据一致性的解决方案，分布式应用程序可以基于它实现诸如数据<strong>发布/订阅</strong>、<strong>负载均衡</strong>、<strong>命名服务</strong>、<strong>分布式协调/通知</strong>、<strong>集群管理</strong>、<strong>Master 选举</strong>、<strong>分布式锁</strong>和<strong>分布式队列</strong>等功能。</p><ul><li><strong>命名服务</strong> - 按名称标识集群中的节点。它类似于DNS，但仅对于节点。</li><li><strong>配置管理</strong> - 加入节点的最近的和最新的系统配置信息。</li><li><strong>集群管理</strong> - 实时地在集群和节点状态中加入/离开节点。</li><li><strong>选举算法</strong> - 选举一个节点作为协调目的的leader。</li><li><strong>锁定和同步服务</strong> - 在修改数据的同时锁定数据。此机制可帮助你在连接其他分布式应用程序（如Apache HBase）时进行自动故障恢复。</li><li><strong>高度可靠的数据注册表</strong> - 即使在一个或几个节点关闭时也可以获得数据。</li></ul><p>分布式应用程序提供了很多好处，但它们也抛出了一些复杂和难以解决的挑战。ZooKeeper框架提供了一个完整的机制来克服所有的挑战。竞争条件和死锁使用<strong>故障安全同步方法</strong>进行处理。另一个主要缺点是数据的不一致性，ZooKeeper使用<strong>原子性</strong>解析。</p><h4 id="benefits-of-zookeeper" tabindex="-1"><a class="header-anchor" href="#benefits-of-zookeeper" aria-hidden="true">#</a> <strong>Benefits of ZooKeeper</strong></h4><p>Here are the benefits of using ZooKeeper −</p><ul><li><strong>Simple distributed coordination process</strong></li><li><strong>Synchronization</strong> − Mutual exclusion and co-operation between server processes. This process helps in Apache HBase for configuration management.</li><li><strong>Ordered Messages</strong></li><li><strong>Serialization</strong> − Encode the data according to specific rules. Ensure your application runs consistently. This approach can be used in MapReduce to coordinate queue to execute running threads.</li><li><strong>Reliability</strong></li><li><strong>Atomicity</strong> − Data transfer either succeed or fail completely, but no transaction is partial.</li></ul><h4 id="benefits-of-distributed-applications" tabindex="-1"><a class="header-anchor" href="#benefits-of-distributed-applications" aria-hidden="true">#</a> <strong>Benefits of Distributed Applications</strong></h4><ul><li><strong>Reliability</strong> − Failure of a single or a few systems does not make the whole system to fail.</li><li><strong>Scalability</strong> − Performance can be increased as and when needed by adding more machines with minor change in the configuration of the application with no downtime.</li><li><strong>Transparency</strong> − Hides the complexity of the system and shows itself as a single entity / application.</li></ul><h4 id="challenges-of-distributed-applications" tabindex="-1"><a class="header-anchor" href="#challenges-of-distributed-applications" aria-hidden="true">#</a> <strong>Challenges of Distributed Applications</strong></h4><ul><li><strong>Race condition</strong> − Two or more machines trying to perform a particular task, which actually needs to be done only by a single machine at any given time. For example, shared resources should only be modified by a single machine at any given time.</li><li><strong>Deadlock</strong> − Two or more operations waiting for each other to complete indefinitely.</li><li><strong>Inconsistency</strong> − Partial failure of data.</li></ul></blockquote><p><img src="https://eddie-typora-image.oss-cn-shenzhen.aliyuncs.com/typora-user-images/image-20221206112822848.png" alt="image-20221206112822848"></p><p>Each one of the components that is a part of the ZooKeeper architecture has been explained in the following table.</p><table><thead><tr><th>Part</th><th>Description</th></tr></thead><tbody><tr><td>Client</td><td>Clients, one of the nodes in our distributed application cluster, access information from the server. For a particular time interval, every client sends a message to the server to let the sever know that the client is alive. Similarly, the server sends an acknowledgement when a client connects. If there is no response from the connected server, the client automatically redirects the message to another server.</td></tr><tr><td>Server</td><td>Server, one of the nodes in our ZooKeeper ensemble, provides all the services to clients. Gives acknowledgement to client to inform that the server is alive.</td></tr><tr><td>Ensemble<br>(ZK集群)</td><td>Group of ZooKeeper servers. The minimum number of nodes that is required to form an ensemble is 3.</td></tr><tr><td>Leader</td><td>Server node which performs automatic recovery if any of the connected node failed. Leaders are elected on service startup.</td></tr><tr><td>Follower</td><td>Server node which follows leader instruction.</td></tr></tbody></table><h2 id="zookeeper-workflow" tabindex="-1"><a class="header-anchor" href="#zookeeper-workflow" aria-hidden="true">#</a> Zookeeper - Workflow</h2><p><img src="https://eddie-typora-image.oss-cn-shenzhen.aliyuncs.com/typora-user-images/image-20230408170626313.png" alt="image-20230408170626313"></p><table><thead><tr><th>Component</th><th>Description</th></tr></thead><tbody><tr><td>Write</td><td>Write process is handled by the leader node. The leader forwards the write request to all the znodes and waits for answers from the znodes. If half of the znodes reply, then the write process is complete.</td></tr><tr><td>Read</td><td>Reads are performed internally by a specific connected znode, so there is no need to interact with the cluster.</td></tr><tr><td>Replicated Database</td><td>It is used to store data in zookeeper. Each znode has its own database and every znode has the same data at every time with the help of consistency.</td></tr><tr><td>Leader</td><td>Leader is the Znode that is responsible for processing write requests.</td></tr><tr><td>Follower</td><td>Followers receive write requests from the clients and forward them to the leader znode.</td></tr><tr><td>Request Processor</td><td>Present only in leader node. It governs write requests from the follower node.</td></tr><tr><td>Atomic broadcasts</td><td>Responsible for broadcasting the changes from the leader node to the follower nodes.</td></tr></tbody></table><blockquote><p>Once a ZooKeeper ensemble starts, it will wait for the clients to connect. Clients will connect to one of the nodes in the ZooKeeper ensemble. It may be a leader or a follower node. Once a client is connected, the node assigns a session ID to the particular client and sends an acknowledgement to the client. If the client does not get an acknowledgment, it simply tries to connect another node in the ZooKeeper ensemble. Once connected to a node, the client will send heartbeats to the node in a regular interval to make sure that the connection is not lost.</p><ul><li><strong>If a client wants to read a particular znode,</strong> it sends a <strong>read request</strong> to the node with the znode path and the node returns the requested znode by getting it from its own database. For this reason, reads are fast in ZooKeeper ensemble.</li><li><strong>If a client wants to store data in the ZooKeeper ensemble</strong>, it sends the znode path and the data to the server. The connected server will forward the request to the leader and then the leader will reissue the writing request to all the followers. If only a majority of the nodes respond successfully, then the write request will succeed and a successful return code will be sent to the client. Otherwise, the write request will fail. The strict majority of nodes is called as <strong>Quorum</strong>.</li></ul><p><strong>Nodes in a ZooKeeper Ensemble</strong></p><p>Let us analyze the effect of having different number of nodes in the ZooKeeper ensemble.</p><ul><li>If we have <strong>a single node</strong>, then the ZooKeeper ensemble fails when that node fails. It contributes to “Single Point of Failure” and it is not recommended in a production environment.</li><li>If we have <strong>two nodes</strong> and one node fails, we don’t have majority as well, since one out of two is not a majority.</li><li>If we have <strong>three nodes</strong> and one node fails, we have majority and so, it is the minimum requirement. It is mandatory for a ZooKeeper ensemble to have at least three nodes in a live production environment.</li><li>If we have <strong>four nodes</strong> and two nodes fail, it fails again and it is similar to having three nodes. The extra node does not serve any purpose and so, it is <strong>better to add nodes in odd numbers, e.g., 3, 5, 7.</strong></li></ul></blockquote><h2 id="zookeeper-系统结构" tabindex="-1"><a class="header-anchor" href="#zookeeper-系统结构" aria-hidden="true">#</a> zookeeper 系统结构</h2><p>zookeeper 提供的名称空间非常类似于标准文件系统，key-value 的形式存储。名称 key 由斜线 <strong>/</strong> 分割的一系列路径元素，zookeeper 名称空间中的每个节点都是由一个路径标识</p><blockquote><p>最主要的是 znode 有四种类型：</p><ul><li>永久节点（除非手动删除，节点永远存在）</li><li>永久有序节点（按照创建顺序会为每个节点末尾带上一个序号如：<code>root-1</code>）</li><li>瞬时节点（创建客户端与 Zookeeper 保持连接时节点存在，断开时则删除并会有相应的通知）</li><li>瞬时有序节点（在瞬时节点的基础上加上了顺序）</li></ul><p>考虑下上文使用 Redis 最大的一个问题是什么？</p><p>其实就是不能实时的更新服务提供者的信息。</p><p>那利用 Zookeeper 是怎么实现的？</p><p>主要看第三个特性：<strong>瞬时节点</strong></p><p>Zookeeper 是一个典型的观察者模式。</p><ul><li>由于瞬时节点的特点，我们的消费者可以订阅瞬时节点的父节点。</li><li>当新增、删除节点时所有的瞬时节点也会自动更新。</li><li>更新时会给订阅者发起通知告诉最新的节点信息。</li></ul><p>这样我们就可以实时获取服务节点的信息，同时也只需要在第一次获取列表时缓存到本地；也不需要频繁和 Zookeeper 产生交互，只用等待通知更新即可。</p><p>并且不管应用什么原因节点 down 掉后也会在 Zookeeper 中删除该信息。</p></blockquote><p><img src="https://eddie-typora-image.oss-cn-shenzhen.aliyuncs.com/typora-user-images/image-20230408181233501.png" alt="image-20230408181233501"></p><p><img src="https://eddie-typora-image.oss-cn-shenzhen.aliyuncs.com/typora-user-images/image-20221206112136402.png" alt="image-20221206112136402"></p><h2 id="相关理论" tabindex="-1"><a class="header-anchor" href="#相关理论" aria-hidden="true">#</a> 相关理论</h2><h3 id="cap理论" tabindex="-1"><a class="header-anchor" href="#cap理论" aria-hidden="true">#</a> CAP理论</h3><p>CAP 理论指出对于一个分布式计算系统来说，<strong>不可能同时满足以下三点</strong>：</p><ul><li><strong>一致性(Consistency)</strong>：在分布式环境中，一致性是指数据在多个副本之间是否能够保持一致的特性，等同于所有节点访问同一份最新的数据副本。在一致性的需求下，当一个系统在数据一致的状态下执行更新操作后，应该保证系统的数据仍然处于一致的状态。</li><li>**可用性(Availability)：**每次请求都能获取到正确的响应，但是不保证获取的数据为最新数据。</li><li>**分区容错性(Partition Tolerance)：**分布式系统在遇到任何网络分区故障的时候，仍然需要能够保证对外提供满足一致性和可用性的服务，除非是整个网络环境都发生了故障。</li></ul><p><img src="https://eddie-typora-image.oss-cn-shenzhen.aliyuncs.com/typora-user-images/image-20221206113122527.png" alt="image-20221206113122527"></p><p>一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。</p><p>在这三个基本需求中，最多只能同时满足其中的两项，<strong>P 是必须的</strong>，因此只能在 <strong>CP</strong> 和 <strong>AP</strong> 中选择，<strong>zookeeper 保证的是 CP</strong>，对比 spring cloud 系统中的注册中心 <strong>Eureka 实现的是 AP</strong>。</p><h3 id="base-理论" tabindex="-1"><a class="header-anchor" href="#base-理论" aria-hidden="true">#</a> BASE 理论</h3><p>BASE 是 ==Basically Available(基本可用)==、==Soft-state(软状态)== 和 ==Eventually Consistent(最终一致性)== 三个短语的缩写。</p><ul><li>**基本可用：**在分布式系统出现故障，允许损失部分可用性（服务降级、页面降级）。</li><li>**软状态：**允许分布式系统出现中间状态。而且中间状态不影响系统的可用性。这里的中间状态是指不同的 data replication（数据备份节点）之间的数据更新可以出现延时的最终一致性。</li><li>**最终一致性：**data replications 经过一段时间达到一致性。</li></ul><p><strong>BASE 理论是对 CAP 中的一致性和可用性进行一个权衡的结果</strong>，理论的核心思想就是：我们无法做到强一致，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性。</p><h2 id="zookeeper-安装配置" tabindex="-1"><a class="header-anchor" href="#zookeeper-安装配置" aria-hidden="true">#</a> Zookeeper 安装配置</h2><h3 id="linux-安装" tabindex="-1"><a class="header-anchor" href="#linux-安装" aria-hidden="true">#</a> Linux 安装</h3>',28),m={href:"https://zookeeper.apache.org/releases.html",target:"_blank",rel:"noopener noreferrer"},f=r(`<p><img src="https://eddie-typora-image.oss-cn-shenzhen.aliyuncs.com/typora-user-images/image-20221206114549536.png" alt="image-20221206114549536"></p><p><img src="https://eddie-typora-image.oss-cn-shenzhen.aliyuncs.com/typora-user-images/image-20221206114605315.png" alt="image-20221206114605315"></p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>[root@192 opt]# tar -zxvf zookeeper-3.4.9.tar.gz #解压缩
$ cd zookeeper-3.4.14 
$ cd conf/ #进去配置文件目录
$ cp zoo_sample.cfg zoo.cfg #复制一份配置文件模板 并命名为zoo.cfg用于启动
$ cd ..
$ cd bin/ #进去到bin目录下
$ sh zkServer.sh start #启动zookeeper
$ sh zkServer.sh status #查看zookeeper状态
$ sh zkCli.sh #启动客户端
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,3);function b(y,v){const o=l("ExternalLinkIcon");return i(),a("div",null,[c,h,p,e("p",null,[e("a",g,[t("Apache ZooKeeper"),n(o)])]),u,e("p",null,[e("a",m,[t("Apache ZooKeeper"),n(o)])]),f])}const k=s(d,[["render",b],["__file","Zookeeper.html.vue"]]);export{k as default};
